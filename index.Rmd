---
title: "ST558 - Project 2"
author: "Sandra Aziz, Simon Weisenhorn"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This project focuses around an online news popularity dataset provided by the
UC Irvine Machine Learning Repository. The dataset consists of 61 total
variables where 58 are considered predictive, 2 are non-predictive, and 1 is the
targeted response. Since 2 of the variables are non-predictive and not of
interest to our summaries, they will be removed when bringing in the data. The
remaining predictor variables consist of information regarding aspects
of online news articles. These aspects include things ranging from the rate
of positive words, the level of subjectivity, the amount of images, and
the number of keywords in the metadata to name just a few of the many variables
that we are interested in exploring their relationship with the target response
variable, which is the number of shares each news article received.
Additionally, there are a six total data channels that break up the dataset
based on which data channel the news article falls under. Each report will be
based on a singular data channel to amass six total reports.  
 
The purpose of this analysis is to first gain a better understanding of how
the relationships between the number of shares change as different predictor
variables change. This exploration will occur in the summarizations section
below and will be investigated on the training dataset after splitting the
full dataset into a 70/30 split of training data and testing data. Following
this investigation, we will enter the methods section, which aims to model the
response through a few different kinds of models. Each model will model the
shares variable as the response and utilize all of the variables labeled
"predictive" as the predictors. The models will also preprocess the training
data and use cross-validation to select the best version of itself. After all
of the models have been created, they will be compared and selected based on
the smallest RMSE value. The purpose of creating multiple models is to ensure
we are picking a model that predicts the testing data the best so that our
predictions are more accurate.

## Loading Libraries

Before we load our data or do any analysis, we will first load the libraries 
needed throughout the project:

```{r Libraries, message=FALSE, warning=FALSE}
library(tidyverse) #for cleaning the data
library(ggplot2) # for creating ggplots
library(stringr) # for str_to_title()
library(caret) # for model training and evaluation
library(gbm) #Needed this library to run the training function for boosted tree
```

## Reading in Dataset

Now, we will read in our data set.  

```{r Data Import}
# reading in the data
data <- read_csv("data/OnlineNewsPopularity.csv", show_col_types=FALSE)
head(data) #viewing the first 6 observations of the data
```

Next, we will subset our data set into one with the desired channel of interest.  

```{r Subset Function}
#This function was written to assist in data filtering

data_subsetter <- function(channelOfInterest) {
  
  if(!(channelOfInterest %in% c("lifestyle", "entertainment", "bus", "socmed", 
                                "tech", "world"))){
    stop("Error: The channel must be lifestyle, entertainment, bus, socmed, 
         tech, or world")
  }
  #This conditional statement ensures that the user passed one of the possible
  #six data channels, otherwise the function is stopped and an error message is
  #presented
  
  subset <- data %>% filter(eval(parse(text=paste0("data_channel_is_", 
                                                channelOfInterest))) == 1)
  #Subsetting the data to filter the rows based on the given data channel
    
  thinner <- subset[, c(14:19)] #Selecting the 6 data channel columns
  thinner <- thinner[, colSums(thinner != 0) == 0] 
  #Extracting the columns that were not selected by the user input
  drops <- names(thinner) #Selecting the names of irrelevant data channels
  drops <- c(drops, "url") 
  #adding the url column to be removed because it is non-predictive
  data2 <- subset[ , !(names(subset) %in% drops)]
  #removing irrelevant data channels from dataset
  
  channelOfInterest <<- str_to_title(channelOfInterest) 
  #Making global variable out of user supplied channel for later uses
  
  return(data2) 
  #Returning dataset with filtered rows based on the selected channel and 
  #removing the other channels that the user did not supply
}
```

```{r Subset of Data}
channel_data <- data_subsetter(params[[1]][1]) #subsetting for given channel
head(channel_data) #inspecting subsetted data
```

Now that we've subset our data set. We will now split it into train and test 
sets for summary and analysis purposes.  

```{r Train/Test Split, warning=FALSE}
set.seed(558) #setting seed for reproducibility 

trainIndex <- createDataPartition(channel_data$shares, p = 0.7, 
                                  list = FALSE)
#Creating indexes for training data 

channelTrain <- channel_data[trainIndex, ] #Creating training dataset
channelTest <- channel_data[-trainIndex, ] #Creating testing dataset

channelTrain_summary <- channelTrain 
#Creating copy of training data so that summaries can be performed on it below
#This is so that summary variables can be added to the training data without 
#having to add them to the test set
```

## Summarizations

After splitting our data into train and test sets, we will now create some 
summary statistics and analysis plots on our train set.  

### The following summarizations were created by Sandra Aziz

```{r summaries 1}
# summary stats for shares
summary_stats <- summary(channelTrain_summary$shares)
summary_stats
```

The statistics above explore the spread of the `shares` variable. If the mean is 
less than the median, the data is skewed to the left. If the median is less than 
the mean, then the data is skewed to the right.  

```{r summaries 2}
# contingency table for number of videos
videos_table <- table(channelTrain_summary$num_videos)
videos_table
```

The contingency table above shows the frequency of the number of videos in each 
observation of our data.  

```{r summaries 3}
ggplot(channelTrain_summary, aes(x = n_tokens_content, y = shares)) +
geom_point() +
labs(x = "Number of words in the content", y = "Number of Shares") +
ggtitle("Shares vs. Number of words in the content")
# Creating ggplot of number of words in the content vs shares

ggplot(channelTrain_summary, aes(x = rate_positive_words, y = shares)) +
geom_point() +
labs(x = "Positive Word Rate", y = "Number of Shares") +
ggtitle("Shares vs. Positive Word Rate")
# Creating ggplot of positive word rate vs shares

ggplot(channelTrain_summary, aes(x = rate_negative_words, y = shares)) +
geom_point() +
labs(x = "Negative Word Rate", y = "Number of Shares") +
ggtitle("Shares vs. Negative Word Rate")
# Creating ggplot of negative word rate vs shares
```

Above are three scatter plots that explore the relationship between the number 
of shares and the number of words in the content, the positive word rate, and 
negative word rate, respectively.  

### The following summarizations were created by Simon Weisenhorn

```{r Numerical Summaries by Day}

sunday_data <- channelTrain_summary %>% filter(weekday_is_sunday == 1) %>% 
  transmute(day="Sunday", shares=shares)
#Creating new dataset of shares for when the day is Sunday

monday_data <- channelTrain_summary %>% filter(weekday_is_monday == 1) %>% 
  transmute(day="Monday", shares=shares)
#Creating new dataset of shares for when the day is Monday

tuesday_data <- channelTrain_summary %>% filter(weekday_is_tuesday == 1) %>% 
  transmute(day="Tuesday", shares=shares)
#Creating new dataset of shares for when the day is Tuesday

wednesday_data <- channelTrain_summary %>% filter(weekday_is_wednesday == 1) %>% 
  transmute(day="Wednesday", shares=shares)
#Creating new dataset of shares for when the day is Wednesday

thursday_data <- channelTrain_summary %>% filter(weekday_is_thursday == 1) %>% 
  transmute(day="Thursday", shares=shares)
#Creating new dataset of shares for when the day is Thursday

friday_data <- channelTrain_summary %>% filter(weekday_is_friday == 1) %>% 
  transmute(day="Friday", shares=shares)
#Creating new dataset of shares for when the day is Friday

saturday_data <- channelTrain_summary %>% filter(weekday_is_saturday == 1) %>% 
  transmute(day="Saturday", shares=shares)
#Creating new dataset of shares for when the day is Saturday

weekly_share_data <- rbind(sunday_data, monday_data, tuesday_data, 
                           wednesday_data, thursday_data, friday_data, 
                           saturday_data)
#Stacking the rows of the seven previous datasets together with rbind

weekly_share_data %>% group_by(day) %>% summarise(Min = min(shares),
                                              firstQuartile = quantile(shares, 
                                                                       0.25),
                                              Avg=mean(shares),
                                              Med=median(shares),
                                              thirdQuartile = quantile(shares, 
                                                                       0.75),
                                              max = max(shares),
                                              stdDev = sd(shares)) %>%
  arrange(match(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", 
                       "Friday", "Saturday")))
#Creating numerical summary of the amount of shares by day of the week
```

We can inspect the numerical summaries of shares split by the day the article 
was posted. These summaries provide an indication of how the amount of shares
shift as the day of the week changes.

```{r Bar Chart by Day}
weekly_share_summaries <- weekly_share_data %>% group_by(day) %>% 
  summarise(Average = mean(shares), Median = median(shares))
#Creating new variables for the average and median amount of shares by day

weekly_share_summaries$day <- factor(weekly_share_summaries$day, 
                                     levels=c("Sunday", "Monday", "Tuesday", 
                                              "Wednesday", "Thursday", "Friday", 
                                              "Saturday"))
#Reordering the days of the week so that they appear in chronological order in 
#the subsequent graph

weekly_share_summaries <- weekly_share_summaries %>% 
  pivot_longer(cols = c(Average, Median),names_to="statistic", 
               values_to = "value")
#Converting data from wide to long format so that the fill type can be used 
#in the graph below

plot4 <- ggplot(weekly_share_summaries, aes(x=day, y=value, fill=statistic)) 
#Creating the base of the plot

plot4 + geom_bar(stat = "identity", position = "dodge") + 
  #utilizing geom_bar to create a side by side bar graph
  labs(x = "Day of Week", y = "Amount of Shares",
       title = paste0("Bar Chart for Center of Shares by Publish Day for 
    the ",channelOfInterest, " Channel")) +
  #Adding descriptive labels
  theme(plot.title = element_text(hjust = 0.5)) +
  #Centering the title
  scale_fill_discrete(name = "Measure of Center")
  #Renaming the legend for clarity
```

We can inspect the measures of the center for the amount of shares by each day 
an article was posted. If the mean (in red) is taller than the median (in blue)
then the amount of shares is skewed right for that particular day. On the other
hand, if the median (in blue) is taller than the mean (in red) then the amount 
of shares is skewed left for that particular day. Finally, if the mean and 
median are similar heights then the amount of shares are symmetrically 
distributed.

```{r Histogram of Shares by Part of Week, warning=FALSE}
weekend_data <- channelTrain_summary %>% filter(is_weekend == 1) %>% 
  transmute(day="Weekend", shares=shares)
#Creating new dataset of shares for when the article was posted on a weekend

weekday_data <- channelTrain_summary %>% filter(is_weekend == 0) %>% 
  transmute(day="Weekday", shares=shares)
#Creating new dataset of shares for when the article was posted on a weekday

new_weekly_share_data <- rbind(weekend_data, weekday_data)
#Stacking the rows of the seven previous datasets together with rbind

maxxlim <- (quantile(new_weekly_share_data$shares, 0.75) - 
              quantile(new_weekly_share_data$shares, 0.25)) * 1.5
#creating the maximum x value by removing any share values that may be
#considered an outlier so that the histogram is easier to view

plot5 <- ggplot(new_weekly_share_data, aes(x=shares, fill=day)) 
#Creating the base of the plot

plot5 + geom_histogram(data=subset(new_weekly_share_data, day == 'Weekday'), 
                       bins=20, alpha = 0.75) +
  #Adding the first histogram layer for the amount of shares if the article 
  #was posted on a weekday
  geom_histogram(data=subset(new_weekly_share_data, day == 'Weekend'), bins=20, 
                 alpha = 0.75) +
  #Adding the second histogram layer for the amount of shares if the article 
  #was posted on a weekend
  labs(x = "Amount of Shares", y = "Frequency", 
       title = paste0("Histogram of Amount of Shares for the ",channelOfInterest,
                      " Channel")) +
  #Adding descriptive labels
  xlim(0,maxxlim) +
  #limiting the x axis to avoid outliers so that the histogram is viewable
  theme(plot.title = element_text(hjust = 0.5)) +
  #Centering the title
  scale_fill_discrete(name = "Part of Week")
  #Renaming the legend for clarity
```

We can inspect the distributions of the amount of shares based on whether the 
article was posted on a weekday or a weekend. If the distributions are shaped
similarly, then we would have no indication that the distribution of the amount
of shares changes for whether the article was posted on a weekday or a weekend.
However, if one of the distributions are shaped differently than the other, 
such as skewed a certain direction or multi-modal, then we would have reason to
believe that the distribution of the amount of shares changes for whether the 
article was posted on a weekday or a weekend.

```{r Contingency Table of Subjectivity}
med_shares <- median(channelTrain_summary$shares)
#Storing the median amount of shares for a cutoff value

channelTrain_summary <- channelTrain_summary %>% 
  mutate(share_indicator = case_when((shares >= med_shares) ~ "High Shares",
                           (shares < med_shares) ~ "Low Shares"),
#Creating a new variable for indicating when shares are higher than 
#the median amount of all shares for this channel
         subjective_indicator = case_when(global_subjectivity >= 0.5 ~ 
                                            "More Subjective",
                           (global_subjectivity < 0.5) ~ "More Objective"))
#Creating a new variable for indicating when articles are more than half
#subjective or less than half subjective

table(channelTrain_summary$share_indicator, 
      channelTrain_summary$subjective_indicator)
#Creating contingency table for sharing indicator with subjective indicator
```

We can inspect the distributions of the sharing indicator with the subjective
indicator. An article with a high sharing rate is one that has the same amount 
of shares or more than the median amount of shares for all articles in the 
dataset, whereas an article with a low sharing rate is one that has less than 
the median amount of shares for all articles in the dataset. Additionally,
an article is considered more objective if the text subjectivity is less than 
.5, whereas an article is considered more subjective if the text subjectivity
is greater than or equal to .5. Thus, these groups provide insight into 
how sharing is affected when the text subjectivity is changed on a binary scale.

```{r Contingency Table of Images}
channelTrain_summary <- channelTrain_summary %>% 
  mutate(image_indicator = case_when(num_imgs == 0 ~ "No Pictures",
                           num_imgs == 1 ~ "One Picture",
                           num_imgs > 1 ~ "Two or More Pictures",))
#Creating a new variable for indicating when the number of images in the article
#is zero, 1, or more than 1.

table(channelTrain_summary$share_indicator, 
      channelTrain_summary$image_indicator)
#Creating contingency table for sharing indicator with image indicator
```

We can inspect the distributions of the sharing indicator with the image
indicator. An article with a high sharing rate is one that has the same amount 
of shares or more than the median amount of shares for all articles in the 
dataset, whereas an article with a low sharing rate is one that has less than 
the median amount of shares for all articles in the dataset. Additionally,
if the article has no pictures then it is labeled no pictures, or if the article
has a singular picture then it is labeled one picture, or if the article has more
than one picture then it is labeled two or more pictures Thus, these groups 
provide insight into how sharing is affected when the amount of pictures are 
changed on a categorical scale.

```{r Contingency Table of Videos}
channelTrain_summary <- channelTrain_summary %>% 
  mutate(video_indicator = case_when(num_videos == 0 ~ "No Videos",
                           num_videos == 1 ~ "One Video",
                           num_videos > 1 ~ "Two or More Videos",))
#Creating a new variable for indicating when the number of videos in the article
#is zero, 1, or more than 1.

table(channelTrain_summary$share_indicator, 
      channelTrain_summary$video_indicator)
#Creating contingency table for sharing indicator with video indicator
```

We can inspect the distributions of the sharing indicator with the video
indicator. An article with a high sharing rate is one that has the same amount 
of shares or more than the median amount of shares for all articles in the 
dataset, whereas an article with a low sharing rate is one that has less than 
the median amount of shares for all articles in the dataset. Additionally,
if the article has no videos then it is labeled no videos, or if the article
has a singular video then it is labeled one video, or if the article has more
than one video then it is labeled two or more videos Thus, these groups 
provide insight into how sharing is affected when the amount of videos are 
changed on a categorical scale.

```{r Scatterplot for Links}
plot6 <- ggplot(channelTrain_summary, aes(x=num_hrefs, y=shares, 
                                          color=num_self_hrefs)) 
#Creating the base of the plot

plot6 + geom_point() + 
  scale_color_gradient(low="blue", high="red", 
                       name="Number of Links 
Published by 
Mashable") +
  #Here I am adding to the plot to create a scatterplot where the points 
  #are colored by amount of links to other articles published by Mashable
  labs(x = "Number of Links in Article", y = "Amount of Shares",
       title = paste0("Amount of Shares vs Number of Links in an Article for the "
                      ,channelOfInterest," Channel")) +
  #Adding descriptive labels
  theme(plot.title = element_text(hjust = 0.5), title= element_text(size=10), 
        legend.title=element_text(size=10)) 
  #Centering the title and scaling text to fit properly
```

We can inspect the trend of the amount of shares as a function of the number of 
links in an article. If the data points display an upward trend, then we would
find an association between a higher amount of shares given a larger number of 
links in an article. If the data points display a downward trend, then we would 
find an association between a lower amount of shares given a smaller number of 
links in an article. Finally, each datapoint has been colored based on the 
amount of links to other articles published by Mashable. A high amount of 
links to other articles published by Mashable are indicated with red datapoints
and a low amount of links to other articles published by Mashable are indicated
with blue datapoints.

```{r Scatterplot for Keywords}
plot7 <- ggplot(channelTrain_summary, aes(x=num_keywords, y=shares)) 
#Creating the base of the plot

plot7 + geom_point() +
  #Here I am adding to the plot to create a scatterplot 
  labs(x = "Number of Keywords in the Metadata", y="Amount of Shares",
       title = paste0("Amount of Shares vs Number of Keywords in the Metadata of 
  an Article for the ",channelOfInterest," Channel")) +
  #Adding descriptive labels
  theme(plot.title = element_text(hjust = 0.5)) 
  #Centering the title
```

We can inspect the trend of the amount of shares as a function of the number of 
keywords in the metadata. If the data points display an upward trend, then we 
would find an association between a higher amount of shares given a larger 
number of keywords in the metadata for an article. If the data points display a 
downward trend, then we would find an association between a lower amount of 
shares given a smaller number of keywords in the metadata for an article. 

```{r Numerical Summaries by Keywords}
channelTrain_summary %>% group_by(num_keywords) %>% summarise(Min = min(shares),
                                              firstQuartile = quantile(shares, 
                                                                       0.25),
                                              Avg=mean(shares),
                                              Med=median(shares),
                                              thirdQuartile = quantile(shares, 
                                                                       0.75),
                                              max = max(shares),
                                              stdDev = sd(shares)) 
#Creating numerical summary of the amount of shares by number of keywords 
#in the metadata
```

We can inspect the numerical summaries of shares split by the number of keywords 
in the metadata for the article. These summaries provide an indication of how 
the amount of shares shift as the number of keywords in the metadata for the 
article changes.  

## Modeling

Now that we've explored some summaries and statistics using our data, we will 
now fit some models using our train set then test them using the test set.  
We will first fit two linear regression models. Linear regression is a 
statistical modeling technique that is used to establish a relationship between 
a dependent variable (in our case, the number of shares) and one or more 
independent (predictor) variables. It assumes a linear relationship between the 
variables, where the dependent variable can be predicted as a linear combination 
of the independent variables. It estimates the coefficients that represent the 
change in the response variable for each unit change in the predictor variables, 
assuming all other variables are held constant. The goal is to estimate the 
coefficients that minimize the difference between the predicted values and the 
actual values of the dependent variable.  
Our first linear regression model will explore a linear fit with interaction 
terms. This model is used to test whether the relationship between the dependent 
and the independent variable changes depending on the value of another 
independent variable.  
Our second linear regression model will explore a linear fit without interaction 
terms. This model assumes that the effect of each predictor on the dependent 
variable is independent of other predictors in the model.  

```{r First Linear Fit, warning=FALSE, message=FALSE}
simon_share_lmfit <- train(shares ~ .^2, data = channelTrain,
                           method = "lm",
                           preProcess = c("center", "scale"),
                           trControl = trainControl(method = "cv", number = 5))
#Fitting linear model with all interactions

summary(simon_share_lmfit)
#viewing the resulting model

pred <- predict(simon_share_lmfit, newdata = channelTest)
#Creating predictions based on the channelTest data
l1 <- postResample(pred, obs = channelTest$shares)
#creating first linear model postResample results object
l1 #viewing how well the first linear model did 
```

```{r Second Linear Fit, warning=FALSE, message=FALSE}
sandra_share_lmfit <- train(shares ~ ., data = channelTrain,
                           method = "lm",
                           preProcess = c("center", "scale"),
                           trControl = trainControl(method = "cv", number = 5))
#Fitting linear model with no interactions

summary(sandra_share_lmfit)
#viewing the resulting model

pred <- predict(simon_share_lmfit, newdata = channelTest)
#Creating predictions based on the channelTest data
l2 <- postResample(pred, obs = channelTest$shares)
#creating second linear model postResample results object
l2 #viewing how well the second linear model did 
```

The next model we will explore is a boosted tree model. A boosted tree is 
an ensemble based model that treats the errors created by previous decision 
trees. By considering the errors of trees in previous rounds, the boosted
tree model forms new trees sequentially where each tree is dependent on the
previous tree. These kinds of models are useful for non-linear data, which make
them great for real world applications.

```{r Boosted Tree, message=FALSE, warning=FALSE}
allTuningParameters <- expand.grid(n.trees=c(25,50,100,150,200), 
                                   interaction.depth=c(1,2,3,4), 
                                   shrinkage=0.1, n.minobsinnode = 10)
#Creating dataframe for the tuneGrid arguement using expand.grid

boostTreeFit <- train(shares ~ ., data = channelTrain,
                      method = "gbm",
                      preProcess = c("center", "scale"),
                      trControl = trainControl(method = "repeatedcv", 
                                               number = 5, repeats=3),
                      tuneGrid=allTuningParameters,
                      verbose=FALSE)
#Fitting the boosted tree model

boostTreeFit
#viewing the resulting model

pred <- predict(boostTreeFit, newdata = channelTest)
#Creating predictions based on the channelTest data
bt <- postResample(pred, obs = channelTest$shares)
#creating boosted tree postResample results object
bt #viewing how well the boosted tree did 
```

The last model we will explore is a random forest model. It is an ensemble 
tree-based model that trains a collection of decision trees using bootstrap 
aggregating (bagging) and feature randomness. It combines the predictions of 
multiple decision trees to make predictions based on the majority vote or 
averaging of the individual trees.  

```{r Random Forests, message=FALSE, warning=FALSE}
randomForestFit <- train(shares ~ ., data = channelTrain,
                      method = "rf",
                      trControl = trainControl(method = "repeatedcv", 
                                               number = 5, repeats = 3),
                      tuneGrid = data.frame(mtry = 1:15))
# Fitting the random forests model

randomForestFit
# Viewing the resulting model

pred <- predict(randomForestFit, newdata = channelTest)
#Creating predictions based on the channelTest data
rf <- postResample(pred, obs = channelTest$shares)
#creating random forest postResample results object
rf #viewing how well the random forest did
```

## Comparison

Now that we've fit and tested the above four models using our train and test 
sets. We will now compare all four models to pick the best one overall.  

```{r Comparison}
modelList <- list(firstLinearModel = l1[[1]], secondLinearModel = l2[[1]], 
                  boostedTree = bt[[1]], randomForest = rf[[1]])
# Storing all RMSE in one list

bestModel <- names(modelList)[which.min(modelList)]
# Finding model with lowest RMSE

paste("The best model with the lowest RMSE was", bestModel, sep=" ")
# Printing model with lowest RMSE
```

The model printed above has the lowest RMSE and, thus, is the best model to 
use for predicted new values.  
